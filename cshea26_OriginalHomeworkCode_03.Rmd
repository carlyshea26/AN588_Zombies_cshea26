---
title: "cshea26_OriginalHomeworkCode_03"
author: "Carly S McDermott"
date: "2025-02-24"
output: 
  rmdformats::readthedown:
---
<center>
![""](https://cdn.dribbble.com/userupload/21087755/file/original-8e60712234abc48e340ff564563ba420.gif)
</center>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rmdformats)
library(curl)
library(tidyverse)
library(ggplot2)
library(gridExtra)
```

```{r}
#First load the data (csv)
zombies <- read.csv("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/refs/heads/master/AN588_Spring25/zombies.csv", header = TRUE, stringsAsFactors = FALSE)
head(zombies) #shortening reading frame to something more manageable 
```

## Calculate the population mean and standard deviation for each quantitative random variable (height, weight, age, number of zombies killed, and years of education). NOTE: You will not want to use the built in var() and sd() commands as these are for samples.
```{r}
#shortening mean to m for creating abbreviations to determine population means
summary(zombies) #one way to see mean values for all of the different columns

mean.height <- mean(zombies$height); mean.height
mean.weight <- mean(zombies$weight); mean.weight
mean.age <- mean(zombies$age); mean.age
mean.zombieskilled <- mean(zombies$zombies_killed); mean.zombieskilled
mean.eduation <- mean(zombies$years_of_education); mean.eduation
#both ways of doing this show the mean values for the sample, but the second method provides a more direct path to getting there 
```
Part two to answer Q1 is calculating the standard deviation for each of the quantitative random variables: 
```{r}
pop_sd <- function(x) {
    sqrt(sum((x - mean(x))^2)/(length(x))) #standard deviation is taking the square root of the population variance here, i could have made it into a separate function for population variance but didn't feel like it
}
pop_sd(zombies$height)
pop_sd(zombies$weight)
pop_sd(zombies$age)
pop_sd(zombies$zombies_killed)
pop_sd(zombies$years_of_education)

#i am wondering if there's a way to condense all of these together into one function instead of doing pop_sd over and over again? 
```

## Use {ggplot} to make boxplots of each of these variables by gender.
```{r}
#I recognize that this looks insane and I fully believe there is a way to make it look less cluttered but I am unsure how

#plot1
plot.height <- ggplot(data = zombies, aes(x = gender, y = height, fill = gender)) + geom_boxplot(na.rm = TRUE, show.legend = FALSE)  #define the variables
plot.height <- plot.height + xlab("Gender") + ylab("Height") + theme_bw() +
                ggtitle("Height") + theme(plot.title = element_text(hjust = 0.5)) # adding title to the plot
#hjust centers it by setting it equal t0 .5

#plot2
plot.weight <- ggplot(data = zombies, aes(x = gender, y = weight, fill = gender)) + geom_boxplot(na.rm = TRUE, show.legend = FALSE) 
plot.weight <- plot.weight + xlab("Gender") + ylab("Weight") + theme_bw() +
                ggtitle("Weight") + theme(plot.title = element_text(hjust = 0.5)) # adding title to the plot

#plot3
plot.age <- ggplot(data = zombies, aes(x = gender, y = age, fill = gender)) + geom_boxplot(na.rm = TRUE, show.legend = FALSE) 
plot.age <- plot.age + xlab("Gender") + ylab("Age") + theme_bw() +
                ggtitle("Age") + theme(plot.title = element_text(hjust = 0.5)) # adding title to the plot

#plot4
plot.zombies_killed <- ggplot(data = zombies, aes(x = gender, y = zombies_killed, fill = gender)) + geom_boxplot(na.rm = TRUE, show.legend = FALSE) 
plot.zombies_killed <- plot.zombies_killed + xlab("Gender") + ylab("Zombies Killed") + theme_bw() +
                ggtitle("Zombies Killed") + theme(plot.title = element_text(hjust = 0.5)) # adding title to the plot

#plot5
plot.years_of_education <- ggplot(data = zombies, aes(x = gender, y = years_of_education, fill = gender)) + geom_boxplot(na.rm = TRUE, show.legend = FALSE) 
plot.years_of_education <- plot.years_of_education + xlab("Gender") + ylab("Years of Education") + theme_bw() +
                ggtitle("Years of Education") + theme(plot.title = element_text(hjust = 0.5)) # adding title to the plot
grid.arrange(plot.height, plot.weight, plot.age,
             plot.zombies_killed, plot.years_of_education, nrow = 2, ncol = 3) #doing this to make them all sit together on one page as 5 boxplots (similar to par function - i install the gridExtra package for this)
```

## Use {ggplot} to make scatterplots of height and weight in relation to age. Do these variables seem to be related? In what way?
```{r}
scat.height <- ggplot(data = zombies, aes(x = age, y = height, color = age)) #making plot
scat.height <- scat.height + scale_color_gradient(low = "blue", high = "green") #adding different colors to differentiate between the two scatterplots
scat.height <- scat.height + xlab("Age") + ylab("Height") + theme_bw() #adding labels for axes
scat.height <- scat.height + geom_point() #making scatterplot!
scat.height

scat.weight <- ggplot(data = zombies, aes(x = age, y = weight, color = age)) #making plot
scat.weight <- scat.weight + scale_color_gradient(low = "pink", high = "purple")
scat.weight <- scat.weight + xlab("Age") + ylab("Weight") + theme_bw() #adding labels for axes
scat.weight <- scat.weight + geom_point() #making scatterplot!
scat.weight

#I want to combine them on one page to visualize the data together
grid.arrange(scat.height, scat.weight, nrow = 1, ncol = 2)
```
Takeaways From Generating Two Scatterplots: Identifying Trends 
- I notice that when plotting Age vs. Weight and Age vs. Height, there appear to be positive correlations in both plots. Younger individuals are shown to be shorter and lower in weight. Differences across the two plots highlights greater variability in the Age vs. Weight, where there is less of a linear correlation (varies a lot)l

## Using histograms and Q-Q plots, check whether the quantitative variables seem to be drawn from a normal distribution. Which seem to be and which do not (hint: not all are drawn from the normal distribution)? For those that are not normal, can you determine from which common distribution they are drawn?
```{r}

```

## Now use the sample() function to sample ONE subset of 30 zombie survivors (without replacement) from this population and calculate the mean and sample standard deviation for each variable. Also estimate the standard error for each variable, and construct the 95% confidence interval for each mean. Note that for the variables that are not drawn from the normal distribution, you may need to base your estimate of the CIs on slightly different code than for the normal…
```{r}

```

## Now draw 99 more random samples of 30 zombie apocalypse survivors, and calculate the mean for each variable for each of these samples. Together with the first sample you drew, you now have a set of 100 means for each variable (each based on 30 observations), which constitutes a sampling distribution for each variable. What are the means and standard deviations of this distribution of means for each variable? How do the standard deviations of means compare to the standard errors estimated in [5]? What do these sampling distributions look like (a graph might help here)? Are they normally distributed? What about for those variables that you concluded were not originally drawn from a normal distribution?
```{r}

```


## 5 Challenges I Faced
#1. Initially I struggled to add a toc because it wouldn’t let me knit the file when I was using the rmd formats package. I got this message: formal argument "toc" matched by multiple actual arguments. I deleted it and I suppose now it has a built in toc and therefore I don’t need to specify. Also I am sorry but this is lowkey an ugly theme I can’t lie.

#2.I struggled with loading my data using the curl function but after looking at the previous modules I realized that I needed to use quotation marks surrounding the link to the data set, oops!

#3.^ I ended up abandoning the use of the curl function because I thought that was the original issue (turns out that I didn't copy the url correctly and that I forgot to use the raw data csv link instead of the link to all of the zombies data). That was definitely a learning curve but I think I understand the correct procedure now. 

#4. 
#5.